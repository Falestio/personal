---
title: "Pengembangan Horizontal Autoscaling dengan IDCloudHost API Menggunakan Grafana Alert dan Traefik sebagai Load Balancer"
description: "An overview of Traefik and its role as an API Gateway in modern web applications."
thumbnail: "https://unsplash.it/640/425"
---

# Pengembangan Horizontal Autoscaling dengan IDCloudHost API Menggunakan Grafana Alert dan Traefik sebagai Load Balancer

IDCloudhost juga menyediakan virtual machine (VM) dengan harga yang relatif terjangkau dibandingkan dengan penyedia layanan cloud lainnya, seperti AWS atau Google Cloud. Penjelasan lebih rinci dapat dilihat pada tabel di bawah ini.

| Provider                        | Harga dalam USD | Harga dalam IDR       |
|----------------------------------|-----------------|-----------------------|
| AWS (On-Demand, T3 Small, 2 CPU, 2 GiB RAM, 60 GB EBS Storage) | $25.03          | Rp 391.939       |
| DigitalOcean Droplet (2 CPU, 2 GiB RAM, 60 GB Storage)         | $18.00          | Rp 281.826       |
| IDCloudHost (2 CPU, 2 GiB RAM, 60 GB Storage)                 | $7.19           | Rp 112.500       |

*Data diambil pada 8 October 2024
- Harga AWS didapat dari AWS Pricing calculator
- Harga DigitalOcean didapat dari halaman pricing Droplets
- Harga IDCloudHost didapat dari halaman console saat akan emmbuat VM baru
- 1 Dollar = Rp 15.657 (8 Oktober 2024)

Meskipun harganya lebih terjangkau, IDCloudHost tidak memiliki fitur selengkap penyedia layanan lain, seperti autoscaling. 

Fitur autoscaling sangat penting untuk menangani peningkatan trafik secara otomatis tanpa memerlukan intervensi manual. Saat ini, IDCloudhost menyediakan fitur self-upgrade dan self-downgrade pada layanannya, tetapi belum mendukung autoscaling otomatis. Meskipun IDCloudhost memungkinkan scaling secara manual, fitur ini tidak seotomatis autoscaling pada layanan cloud besar lainnya.

Namun, IDCloudhost menyediakan API yang dapat digunakan untuk mengelola setiap sumber daya yang dimiliki, termasuk membuat dan menghapus VM. API ini memungkinkan pengguna untuk melakukan scale up dan scale down sesuai kebutuhan. Artikel ini akan memberikan panduan cara melakukannya.

## Sistem yang Akan Dibuat

Gambar dibawah adalah gambaran umum dari sistem autoscaling yang akan dibuat
::image-display{src="/blog/idcloudhost-autoscaling/general-archi.svg"}
::

- `Service Clones`  
Service clones adalah kumpulan virtual machine yang menjalankan layanan tertentu dan akan di-autoscale sesuai kebutuhan. Kelompok virtual machine ini dibuat dari sebuah "service seed," yaitu virtual machine utama yang berfungsi sebagai template. Service seed berisi aplikasi dan konfigurasi yang diperlukan, dan setiap service clone yang dibuat merupakan salinan dari service seed, dengan aplikasi dan konfigurasi yang sama. Dengan demikian, service clones dapat dengan cepat disiapkan berdasarkan konfigurasi standar dari service seed, memastikan konsistensi di seluruh lingkungan autoscaling.

- `Traefik API Gateway & Load Balancer`  
Traefik adalah API gateway yang berfungsi sebagai lapisan keamanan sebelum akses ke layanan. Dengan Traefik, kita dapat mengimplementasikan autentikasi, rate limiting, CORS, dan fitur keamanan lainnya. Selain itu, Traefik juga bertindak sebagai load balancer yang mendistribusikan request ke layanan. Saat ini, [Traefik hanya mendukung metode round robin](https://doc.traefik.io/traefik/routing/services/#load-balancing), di mana lalu lintas dibagi secara bergiliran. Misalnya, jika terdapat dua server, permintaan pertama akan diarahkan ke server satu, permintaan kedua ke server dua, dan permintaan ketiga kembali ke server satu dan seterusnya.

- `Grafana & Prometheus Monitoring Server`
Grafana dan Prometheus digunakan untuk monitoring dan pengiriman notifikasi. Prometheus berperan sebagai sumber data, sementara Grafana digunakan untuk visualisasi data dan penerapan fungsi alert yang dapat memicu scale up atau scale down layanan.

- `IDCloudHost API`  
IDCloudHost menyediakan API untuk berinteraksi dengan sumber daya yang dimiliki, termasuk mengelola jaringan VM dan melakukan operasi seperti membaca, membuat, memperbarui, atau menghapus sumber daya.

- `IDCloudHost VPC Network`  
VPC memungkinkan server berkomunikasi melalui jaringan privat, yang mengurangi area potensi serangan oleh hacker karena hanya IP publik dari Traefik yang akan diekspos.

::info-box{type="question" title="Kenapa tidak menggunakan load balancer dari IdCloudHost?"}
Kendala utama dalam menggunakan load balancer bawaan IDCloudhost adalah keterbatasan pengendalian. Load balancer ini hanya mendukung metode session persistence yang tidak dapat diubah. Selain itu, biaya penggunaannya relatif tinggi, terutama jika hanya digunakan untuk metode round robin.
::

## Overview Alur Kerja Sistem

Gambar dibawah menunjukan bagaimana cara sistem bekerja secara umum
::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-umum.svg"}
::

1. Pengguna mengirim permintaan ke endpoint yang diekspos oleh Traefik melalui HTTPS.
2. Traefik berfungsi sebagai load balancer dan meneruskan permintaan ke layanan sesuai giliran, menggunakan metode round robin.
3. Data dari virtual machine setiap layanan dikirim ke server monitoring yang menjalankan Grafana dan Prometheus.
4. Ketika beban CPU melebihi atau kurang dari ambang batas yang ditentukan, server monitoring akan mengirim perintah ke API IDCloudhost untuk melakukan scale up atau scale down, menggunakan Grafana alert.
5. API IDCloudhost kemudian akan melakukan scale up dengan menggandakan service seed untuk membuat service clone baru, atau melakukan scale down dengan menghapus service clone dengan nomor urut tertinggi.
6. Jika service clone berhasil dibuat (scale up), maka akan terhubung dengan Traefik dan server monitoring. Jika berhasil dihapus (scale down), koneksi antara Traefik dan server monitoring akan diputus.

## Penjelasan Detail Cara Kerja Scale Up
::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-detail-1.png"}
::

Gambar diatas menunjukkan sebuah keadaan dimana event scale up akan dijalankan, yaitu ketika server menerima permintaan yang tinggi, mengakibatkan penggunaan CPU melebihi batas yang diinginkan. Hal ini akan terdeteksi oleh Prometheus dan Grafana, yang kemudian memicu sebuah event. Event tersebut juga bisa menangani kondisi di mana permintaan terlalu sedikit, sehingga menyebabkan sumber daya tidak terpakai.

::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-detail-2.png"}
::

Tahapan untuk event scale-up dijelaskan pada gambar kedua:

1. Banyak lalu lintas yang datang menyebabkan layanan mengalami penggunaan CPU yang tinggi, yang pada akhirnya menghasilkan kesalahan respons kepada pengguna.
2. Prometheus mengumpulkan data penggunaan CPU dan memicu Grafana alert untuk memulai proses scale-up.
3. Grafana alert akan merespons dengan memanggil webhook ke server Express yang bertugas menangani event scale-up.
4. Webhook handler pertama akan berinteraksi dengan API IDCloudhost untuk melakukan cloning terhadap service seed.
5. Setelah virtual machine layanan berhasil di-clone, webhook handler akan memperbarui daftar target di server Prometheus untuk menyertakan server yang baru dibuat.
6. Webhook handler kemudian akan mengirim permintaan ke target updater pada server Traefik untuk memperbarui daftar target load balancer, memasukkan server baru ke dalam daftar target.
7. Target updater pada server Traefik akan memperbarui daftar IP dan menambahkan alamat IP privat dari service clone yang baru.

::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-detail-3.png"}
::

Gambar ketiga menunjukkan hasil dari operasi di atas:

1. Service yang baru di-clone dari service seed pada langkah ke-4 dari gambar sebelumnya. Semua konfigurasi dan aplikasi dari service seed akan digandakan, termasuk integrasi dengan Prometheus, sehingga service siap digunakan tanpa konfigurasi manual tambahan.
2. Koneksi antara service yang baru di-clone dan Prometheus pada server monitoring. Prometheus akan memonitor data dari service ini, yang akan digunakan Grafana untuk menampilkan dashboard dan mengirimkan alert jika diperlukan.
3. Koneksi antara Traefik dan service yang baru di-clone, terbentuk pada langkah keenam dari operasi sebelumnya. Traefik akan menangani operasi API gateway seperti CORS, pembatasan kecepatan (rate limiting), dan load balancing di antara semua service yang terhubung. 

Dengan penjelasan ini, proses scaling menjadi lebih jelas, dan koreksi teknis sudah diterapkan agar sesuai dengan cara kerja Prometheus dan Grafana.

## Penjelasan Detail Cara Kerja Scale Down
::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-scale-down-1.png"}
::

Event scale down dimuali ketika server menerima permintaan yang lebih randah dari biasanya. Ini menyebabkan CPU Usage yang rendah dan tidak ideal secara cost jika kita menghidupkan dua server dengan beban pekerjaan yamg bisa dilakukan satu server

Berikut adalah tahapan yang akan dilakukan untuk melakukan scale down

::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-scale-down-2.png"}
::

Proses yang terhadi sama dengan event scale up. Hanya saja kita akan melakukan penghapusan terhadap hasil server clone dan menghapus koneksi yang ada di Traefik dan server monitoring

Gambar dibawah ini adalah hasil dari event scale down

::image-display{src="/blog/idcloudhost-autoscaling/cara-kerja-scale-down-3.png"}
::

1. Daftar server menyisakan service-seed
2. Koneksi server clone yang lama ke monitoring server telah dihapus
3. Koneksi server cloen yang lama ke Traefik telah dihapus

## Menghindari Trashing Karena Konfigurasi Threshold yang Tidak Optimal
Dalam menentukan ambang batas (threshold) kapan sistem harus melakukan scale-up dan scale-down, kita harus menentukannya dengan cermat. Jika tidak, dapat beresiko terjadi *thrashing*. *Thrashing* adalah kondisi di mana server terus-menerus melakukan **scale-down** dan **scale-up** secara berulang tanpa henti. Kondisi ini dapat menyebabkan penggunaan sumber daya yang tidak efisien dan membebani sistem, seperti yang dijelaskan pada gambar di bawah.

::image-display{src="/blog/idcloudhost-autoscaling/thrashing.svg"}
::

1. Service clone dengan satu VM mengalami beban CPU 70%, yang melebihi ambang batas (threshold) untuk scale-up.
2. Sistem melakukan scale-up.
3. VM baru berhasil di-clone dan terhubung ke load balancer serta server monitoring.
4. Beban terbagi secara merata antara dua VM, sehingga rata-rata penggunaan CPU turun menjadi 35%, yang berada di bawah ambang batas untuk scale-down.
5. Sistem kemudian melakukan scale-down.
6. Beban CPU kembali naik ke 70%, menyebabkan sistem melakukan scale-up lagi. Kejadian ini terus berulang, menciptakan siklus yang disebut thrashing.

(kurang solusi untuk masalah)

## Menghindari Thrashing Karena Volume Request yang Fluktuatif
(kurang penjelasan bagaimana thrashing bisa terjaid karena volume request yang terjadi)

Penambahan Grace Period atau Stabilization Window
Tambahkan **grace period** atau **stabilization window**, di mana sistem hanya akan scale down jika load di bawah threshold selama periode waktu tertentu (misalnya, selama 5 menit berturut-turut). Ini mencegah scale down terlalu cepat karena perubahan beban yang bersifat sementara.

## Implementasi Service

Server service akan diimplementasikan pada Virtual machine adalah Judge0 dengan operating system Ubuntu, Judge0 akan diinstal dan dijalankan menggunakan Docker pada port 2358. Pada sistem yang sama akan dipasang node exporter untuk mengirimkan data VM ke server monitoring.

### Service

Instalasi judge0 mengikuti panduan dari dokumentasi resmi https://github.com/judge0/judge0/releases

Pastikan service Anda berjalan pada port yang diinginkan dan dapat diakses dengan http request

### Prometheus Client

Sumber: https://www.linode.com/docs/guides/how-to-install-prometheus-and-grafana-on-ubuntu/#how-to-install-and-configure-node-exporter-on-the-client

Agar sebuah sistem dapat di monitor oleh prometheus diperlukan semacam client untuk mengekspor data sistem. Kita menginstall Node Exporter sebagai client untuk mengirim data ke server monitoring.

Ikut instruksi dibawah untuk menginstall Node Exporter.

> When Node Exporter is running, its collection of statistics is available on port `9100`. This port is accessible on the internet and anyone running Prometheus elsewhere can potentially collect them. If you are using a firewall, you must open port `9100` using the command `sudo ufw allow 9100`.

1. Lihat halaman ini https://prometheus.io/download/#node_exporter untuk mengetahui versi terbaru dari Node Exporter
2. Instal versi terbaru Node Exporter menggunakan `wget`

   ```
   wget https://github.com/prometheus/node_exporter/releases/download/v1.8.2/node_exporter-1.8.2.linux-amd64.tar.gz
   ```

   Cukup ganti `1.8.2` dengan versi terbaru

3. Ekstrak aplikasi.

   ```
   tar xvfz node_exporter-*.tar.gz
   ```

4. Pindahkan executable `node_exporter` kedalam folder `usr/local/bin` sehingga bisa diakses seluruh sistem

   ```
   sudo mv node_exporter-1.5.0.linux-amd64/node_exporter /usr/local/bin
   ```

5. (**Optional**) Hapus sisa file

   ```
   rm -r node_exporter-1.5.0.linux-amd64*
   ```

6. Jalankan command berikut untuk melihat status instalasi node_exporter

   ```
   node_exporter
   ```

   Node Exporter berhasil diinstall, kita sudah dapat menjalankan Node Exporter. Namun kita harus menjalankan Node Exporter sebagai system service agar dapat dijalankan ketika server mulai. Ini memungkinkan ketika kita melakukan clone server, Node Exporter akan langsung berjalan harus memulai nya secara manual.

7. Pertama buatlah user untuk node exporter

   ```
   sudo useradd -rs /bin/false node_exporter
   ```

8. Buatlah service file yang akan digunakan oleh `systemctl`. File harus bernama`node_exporter.service`

   ```
   sudo nano /etc/systemd/system/node_exporter.service
   ```

   **File: /etc/systemd/system/node_exporter.service**

   ```
   **[**Unit**]**Description**=**Node Exporter
   Wants**=**network-online.target
   After**=**network-online.target

   **[**Service**]**User**=**node_exporter
   Group**=**node_exporter
   Type**=**simple
   Restart**=**on-failure
   RestartSec**=**5s
   ExecStart**=**/usr/local/bin/node_exporter

   **[**Install**]**WantedBy**=**multi-user.target
   ```

9. Untuk menjalankan Node Exporter secara otomatis ketika server dimulai (boot time), jalankan command `systemctl endable`

   ```
   sudo systemctl enable node_exporter
   ```

10. Reload `systemctl` daemon, Mulai node_exporter dan cek statusnya

    ```
    sudo systemctl daemon-reload
    sudo systemctl start node_exporter
    sudo systemctl status node_exporter
    ```

    ```
    node_exporter.service - Node Exporter
    Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)
    Active: active (running) since Tue 2023-04-11 13:48:06 UTC; 4s ago
    ```

11. Cek url [http://](http://localhost)localhost:9100/metrics untuk melihat apakah node exporter sudah berjalan

```
curl http://localhost:9100/
```

- something

## Implementasi API Gateway dan Load Balancer

Traefik akan berfungsi sebagai API Gateway, namun dalam sistem ini, fokus utama adalah pada fitur load balancing. Sistem akan menggunakan load balancer berbasis file, di mana target load balancer akan disimpan dalam file konfigurasi. Dengan mengaktifkan fitur watch pada file tersebut, Traefik akan secara otomatis memperbarui target load balancing tanpa perlu melakukan restart aplikasi saat terjadi perubahan.

### Instalasi

1. Install Traefik binary

cek versi traefik terbaru di https://github.com/traefik/traefik/releases

```
wget https://github.com/traefik/traefik/releases/download/v3.1.4/traefik_v3.1.4_linux_amd64.tar.gz
```

1. ekstrak

```
tar -zxvf traefik_v3.1.4_linux_amd64.tar.gz
```

1. jalankan (bisa dipindahkan ke usr/bin)

```
./traefik --help
```

### Konfigurasi Provider

1. Buat basic provider setup

https://doc.traefik.io/traefik/providers/file/

jika anda ingin melakukan request https

Static config (/etc/traefik/static.yaml)

```yaml
entryPoints:
  web:
    address: ":80"

  websecure:
    address: ":443"

certificatesResolvers:
  myresolver:
    acme:
      email: your-email@example.com
      storage: acme.json
      httpChallenge:
        entryPoint: web

providers:
  file:
    directory: /etc/traefik/configs
    watch: true
```

Dynamic config (/etc/traefik/config/dynamic.yaml)

```yaml
http:
  routers:
    submissions:
	    entrypoints:
		    - "websecure"
      rule: "Host(`submissions.pojokoding.my.id`) && Path(`/submissions`)"
      service: "submissions"
      tls:
        certResolver: myresolver
```

Services config (/etc/traefik/config/services.yaml)

```yaml
http:
	services:
		submissions:
			loadBalancer:
				servers:
				- url: "http://<private-ip-services>:2358/"
```

- Konfigurasi izin read and write file

Kita perlu mengizinkan agar file `/etc/traefik/config/services.yaml` dapat diupdate oleh file bash.

```yaml

```

### Konfigurasi Sistem Update Target Load Balancer

Kita akan membuat sebuah server express untuk mengangi event scale down dan event scale up

Tugas dari sistem ini adalah untuk melakukan udpate daftar url pada `loadbalancer.servers`

Sistem ini akan menjalankan file bash untuk melakukan update file konfigurasi dinamis traefik

### Pembuatan File Bash

file bash ini akan melakukan update terhadap daftar servers di load balancer

(update-services.bash)

```bash
#!/bin/bash

# Path ke file services.yaml
SERVICES_FILE="/etc/traefik/config/services.yaml"

# Cek apakah ada parameter yang diberikan
if [ "$#" -lt 1 ]; then
  echo "Usage: $0 <url1> <url2> ... <urlN>"
  exit 1
fi

# Tulis ulang services.yaml dengan daftar server baru
echo "http:" > $SERVICES_FILE
echo "  services:" >> $SERVICES_FILE
echo "    submissions:" >> $SERVICES_FILE
echo "      loadBalancer:" >> $SERVICES_FILE
echo "        servers:" >> $SERVICES_FILE

# Loop melalui semua parameter yang diberikan (URL list)
for SERVICE_URL in "$@"; do
  echo "          - url: \"$SERVICE_URL\"" >> $SERVICES_FILE
done

echo "Update completed."
```

agar file ini dapat dijalankan kita harus mengkonfigurasi file ini sebagai executable

```bash
chmod +x update-services.sh
```

Berikut contoh menjalankan file ini

```bash
./update-services.sh http://10.10.10.10 http://11.11.11.11 http://12.12.12.12
```

hasilnya

```bash
$ cat services.yaml
http:
  services:
    submissions:
      loadBalancer:
        servers:
          - url: "http://10.10.10.10:2358"
          - url: "http://11.11.11.11"
          - url: "http://12.12.12.12"
```

### Pembuatan service express untuk menerima daftar server terbaru

```jsx
touch index.js
```

Lakukan inisiasi aplikasi express terbaru lalu masukan kode berikut pada index.js

```jsx
const express = require("express");
const { exec } = require("child_process");
const path = require("path");

const app = express();
const PORT = 3000;

app.use(express.json());

app.post("/update-servers", (req, res) => {
  const { servers } = req.body;

  if (!servers || !Array.isArray(servers)) {
    return res
      .status(400)
      .json({ message: "Invalid request body. Expected an array of servers." });
  }

  const serverArgs = servers.map((url) => `"${url}"`).join(" ");

  const scriptPath = "./update-services.sh";

  exec(`${scriptPath} ${serverArgs}`, (error, stdout, stderr) => {
    if (error) {
      console.error(`Error executing script: ${stderr}`);
      return res
        .status(500)
        .json({ message: "Failed to update services.yaml", error: stderr });
    }

    console.log(`Script output: ${stdout}`);
    return res
      .status(200)
      .json({ message: "services.yaml updated successfully", output: stdout });
  });
});

app.listen(PORT, () => {
  console.log(`Server is running on port ${PORT}`);
});
```

Gunakan PM2 untuk menjalankan service

1. **Install PM2** jika belum terpasang:

   ```bash
   npm install pm2 -g
   pm2 start index.js
   ```

- Melihat daftar aplikasi yang sedang berjalan:
  ```bash
  pm2 list
  ```
- Menyimpan konfigurasi agar server Express tetap berjalan setelah reboot:
  ```bash
  pm2 save
  pm2 startup
  ```

PM2 akan menjalankan Express server dalam mode daemon, sehingga akan tetap berjalan meskipun terminal ditutup.

jalankan perintah dibawah untuk melihat hasilnya

```
curl -X POST http://localhost:3000/update-servers \
  -H "Content-Type: application/json" \
  -d '{"servers": ["http://server1.example.com", "http://server2.example.com"]}'
```

## Implementasi Monitoring

Pada bagian artikel sebelumnya kita telah melakukan setup prometheus pada server service. Pada bagian ini kita akan membuat prometheus pada sisi server monitoring untuk menerima data dari kumpulan service

Lalu kita akan melakukan setup grafana untuk menvisualisasikan data yang didapat dari prometheus dan setup Alerting untuk melakukan event scale up dan scale down

### Download dan install prometheus

https://www.linode.com/docs/guides/how-to-install-prometheus-and-grafana-on-ubuntu/#how-to-configure-prometheus-as-a-service

Prometheus dapat diunduh sebagai binary yang sudah dikompilasi dari repositori GitHub. Repositori unduhan Prometheus mencantumkan rilis terbaru dari Prometheus. Halaman GitHub Prometheus juga menyediakan instruksi tentang cara membangun Prometheus dari kode sumber atau menjalankannya sebagai kontainer Docker. Untuk mengunduh Prometheus, ikuti langkah-langkah berikut.

Kunjungi halaman unduhan Prometheus dan catat rilis terbaru. Rilis LTS terbaru ditandai dengan jelas di situs tersebut.

Gunakan `wget` untuk mengunduh Prometheus ke server pemantauan. Tautan target memiliki format seperti ini: `https://github.com/prometheus/prometheus/releases/download/v[release]/prometheus-[release].linux-amd64.tar.gz`. Gantilah string `[release]` dengan rilis aktual yang akan diunduh. Sebagai contoh, perintah berikut mengunduh rilis 2.37.6.

```bash
wget <https://github.com/prometheus/prometheus/releases/download/v2.37.6/prometheus-2.37.6.linux-amd64.tar.gz>
```

Ekstrak file Prometheus yang diarsipkan.

```bash
tar xvfz prometheus-*.tar.gz
```

(Opsional) Setelah file diekstrak, hapus arsip atau pindahkan ke lokasi lain untuk penyimpanan.

```bash
rm prometheus-*.tar.gz
```

Buat dua direktori baru yang akan digunakan oleh Prometheus. Direktori `/etc/prometheus` menyimpan file konfigurasi Prometheus. Direktori `/var/lib/prometheus` menyimpan data aplikasi.

```bash
sudo mkdir /etc/prometheus /var/lib/prometheus
```

Masuk ke direktori utama dari folder prometheus yang diekstrak. Gantilah nama direktori sesuai dengan rilis sebenarnya, misalnya `prometheus-2.37.6.linux-amd64`.

```bash
cd prometheus-2.37.6.linux-amd64
```

Pindahkan direktori `prometheus` dan `promtool` ke direktori `/usr/local/bin/`. Ini membuat Prometheus dapat diakses oleh semua pengguna.

```bash
sudo mv prometheus promtool /usr/local/bin/
```

Pindahkan file konfigurasi YAML `prometheus.yml` ke direktori `/etc/prometheus`.

```bash
sudo mv prometheus.yml /etc/prometheus/prometheus.yml
```

Direktori `consoles` dan `console_libraries` berisi sumber daya yang diperlukan untuk membuat konsol yang disesuaikan. Fitur ini lebih lanjut dan tidak dibahas dalam panduan ini. Namun, file-file ini juga harus dipindahkan ke direktori `/etc/prometheus` jika suatu saat diperlukan.

Catatan:
Setelah direktori ini dipindahkan, hanya file `LICENSE` dan `NOTICE` yang tersisa di direktori asli. Cadangkan dokumen ini ke lokasi lain dan hapus direktori `prometheus-releasenum.linux-amd64`.

```bash
sudo mv consoles/ console_libraries/ /etc/prometheus/
```

Verifikasi bahwa Prometheus berhasil diinstal dengan menggunakan perintah berikut:

```bash
prometheus --version
```

Contoh output:

```bash
prometheus, version 2.37.6 (branch: HEAD, revision: 8ade24a23af6be0f35414d6e8ce09598446c29a2)
build user:       root@5f96027a7c3e
build date:       20230220-09:36:40
go version:       go1.19.6
platform:         linux/amd64
```

### Konfigurasi Prometheus

Meskipun Prometheus bisa dijalankan dan dihentikan langsung dari command line, lebih praktis kalau dijalankan sebagai service menggunakan `systemctl`. Ini memungkinkan Prometheus berjalan di background.

Sebelum Prometheus bisa memonitor sistem eksternal, konfigurasi tambahan perlu ditambahkan ke file `prometheus.yml`. Namun, Prometheus sudah dikonfigurasi untuk memonitor dirinya sendiri, jadi kita bisa melakukan tes sederhana dulu. Untuk konfigurasi Prometheus, ikuti langkah-langkah berikut.

Buat user untuk Prometheus. Perintah berikut akan membuat user sistem:

```bash
sudo useradd -rs /bin/false prometheus

```

Ubah kepemilikan dua direktori yang sudah dibuat sebelumnya ke user `prometheus` yang baru.

```bash
sudo chown -R prometheus: /etc/prometheus /var/lib/prometheus

```

Untuk menjalankan Prometheus sebagai service, buat file `prometheus.service` dengan perintah ini:

```bash
sudo vi /etc/systemd/system/prometheus.service

```

Masukkan konten berikut ke dalam file tersebut:

```
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
Restart=on-failure
RestartSec=5s
ExecStart=/usr/local/bin/prometheus \\
    --config.file /etc/prometheus/prometheus.yml \\
    --storage.tsdb.path /var/lib/prometheus/ \\
    --web.console.templates=/etc/prometheus/consoles \\
    --web.console.libraries=/etc/prometheus/console_libraries \\
    --web.listen-address=0.0.0.0:9090 \\
    --web.enable-lifecycle \\
    --log.level=info

[Install]
WantedBy=multi-user.target

```

Beberapa poin penting dari file ini:

- Bagian `Wants` dan `After` diatur ke `network-online.target` untuk memastikan Prometheus berjalan setelah koneksi jaringan aktif.
- `User` dan `Group` diatur ke `prometheus` supaya hanya user ini yang menjalankan Prometheus.
- `ExecStart` menentukan lokasi file eksekusi Prometheus dan opsi defaultnya.
- `-config.file` menentukan lokasi file konfigurasi sebagai `/etc/prometheus/prometheus.yml`.
- `-storage.tsdb.path` menentukan direktori penyimpanan data aplikasi di `/var/lib/prometheus/`.
- `-web.listen-address` diatur ke `0.0.0.0:9090`, sehingga Prometheus bisa menerima koneksi di semua interface jaringan.
- `-web.enable-lifecycle` memungkinkan pengguna untuk me-reload file konfigurasi tanpa restart Prometheus.

Setelah itu, reload daemon systemctl:

```bash
sudo systemctl daemon-reload

```

(Opsional) Gunakan perintah `systemctl enable` agar Prometheus otomatis mulai saat sistem di-boot. Kalau tidak, Prometheus harus dijalankan manual.

```bash
sudo systemctl enable prometheus

```

Jalankan service Prometheus dan cek statusnya untuk memastikan sudah aktif.

```bash
sudo systemctl start prometheus
sudo systemctl status prometheus

```

Contoh output status:

```bash
prometheus.service - Prometheus
Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)
Active: active (running) since Mon 2023-04-10 13:06:50 UTC; 7s ago
```

Akses interface web dan dashboard Prometheus di `http://local_ip_addr:9090`. Ganti `local_ip_addr` dengan alamat IP server monitoring. Karena menggunakan file konfigurasi default, informasi yang ditampilkan masih terbatas.

Di dashboard Prometheus, file `prometheus.yml` default punya direktif untuk mengambil data dari localhost. Klik `Status` dan pilih `Targets` untuk melihat semua target. Seharusnya hanya ada target Prometheus lokal yang ditampilkan.

Node klien sekarang siap untuk dimonitoring. Untuk menambahkan klien ke dalam file `prometheus.yml`, ikuti langkah-langkah berikut:

Pada server monitoring yang menjalankan Prometheus, buka file `prometheus.yml` untuk diedit.

```bash
sudo vi /etc/prometheus/prometheus.yml

```

Temukan bagian berjudul `scrape_configs`, yang berisi daftar `job`. Saat ini, ada satu job bernama `prometheus`. Job ini memonitor tugas lokal Prometheus di port 9090. Di bawah job `prometheus`, tambahkan job kedua dengan `job_name` bernama `remote_collector`. Masukkan informasi berikut:

- Interval pengambilan data (`scrape_interval`) adalah 10 detik (`10s`).
- Di dalam `static_configs` pada atribut `targets`, tambahkan daftar alamat IP yang ingin dipantau. Pisahkan setiap entri menggunakan koma.
- Tambahkan nomor port `:9100` ke setiap alamat IP.
- Untuk memonitor server lokal, tambahkan entri `localhost:9100` ke daftar tersebut.

Entri tersebut seharusnya terlihat seperti contoh berikut. Ganti `remote_addr` dengan alamat IP sebenarnya dari klien.

```yaml
File: /etc/prometheus/prometheus.yml
---
- job_name: "remote_collector"
  scrape_interval: 10s
  static_configs:
    - targets: ["remote_addr:9100"]
```

Untuk menyegarkan Prometheus segera, restart service Prometheus.

```bash
sudo systemctl restart prometheus

```

Menggunakan browser, kunjungi kembali portal web Prometheus di port 9090 pada server monitoring. Pilih `Status` lalu `Targets`. Sebuah link kedua untuk job `remote_collector` akan muncul, yang menuju port 9100 pada klien. Klik link tersebut untuk melihat statistik.

### Install Grafana

Prometheus sekarang mengumpulkan statistik dari klien yang terdaftar di bagian `scrape_configs` pada file konfigurasinya. Namun, informasi tersebut hanya dapat dilihat dalam bentuk data mentah yang sulit dibaca dan kurang berguna.

Grafana menyediakan antarmuka untuk melihat statistik yang dikumpulkan oleh Prometheus. Instal Grafana pada server yang sama yang menjalankan Prometheus dan tambahkan Prometheus sebagai sumber data. Setelah itu, instal satu atau lebih panel untuk menginterpretasikan data. Untuk menginstal dan mengonfigurasi Grafana, ikuti langkah-langkah berikut:

Instal beberapa utilitas yang dibutuhkan menggunakan apt.

```bash
sudo apt-get install -y apt-transport-https software-properties-common

```

Impor kunci GPG Grafana.

```bash
sudo wget -q -O /usr/share/keyrings/grafana.key <https://apt.grafana.com/gpg.key>

```

Tambahkan repository "stable releases" Grafana.

```bash
echo "deb [signed-by=/usr/share/keyrings/grafana.key] <https://apt.grafana.com> stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list

```

Perbarui paket di repository, termasuk paket Grafana yang baru.

```bash
sudo apt-get update

```

Instal versi open-source dari Grafana.

> Catatan
>
> Untuk menginstal Grafana Enterprise, gunakan perintah `sudo apt-get install grafana-enterprise` sebagai gantinya.

```bash
sudo apt-get install grafana

```

Muat ulang daemon systemctl.

```bash
sudo systemctl daemon-reload

```

Aktifkan dan mulai server Grafana. Menggunakan `systemctl enable` mengonfigurasi server untuk meluncurkan Grafana saat sistem booting.

```bash
sudo systemctl enable grafana-server.service
sudo systemctl start grafana-server

```

Periksa status server Grafana dan pastikan dalam kondisi aktif.

```bash
sudo systemctl status grafana-server

```

```
grafana-server.service - Grafana instance
Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled)
Active: active (running) since Tue 2023-04-11 17:31:53 UTC; 9s ago

```

### Hubungkan grafana dengan prometheus dan install dashboard

Semua komponen sistem sekarang sudah terinstal, tetapi Grafana dan Prometheus belum diatur untuk berinteraksi. Langkah-langkah konfigurasi yang tersisa, termasuk menambahkan Prometheus sebagai sumber data dan mengimpor panel dashboard, dapat dilakukan menggunakan antarmuka web Grafana.

Untuk mengintegrasikan Grafana dan Prometheus, ikuti langkah-langkah di bawah ini:

Menggunakan browser web, kunjungi port 3000 pada server monitoring. Misalnya, masukkan `http://local_ip_addr:3000`, ganti `local_ip_addr` dengan alamat IP sebenarnya. Grafana akan menampilkan halaman login. Gunakan nama pengguna `admin` dan kata sandi default `password`. Ubah kata sandi ke nilai yang lebih aman saat diminta.

**Halaman Login Grafana**

Setelah berhasil mengubah kata sandi, Grafana akan menampilkan **Grafana Dashboard**.

Untuk menambahkan Prometheus sebagai sumber data, klik simbol roda gigi yang mewakili **Configuration**, lalu pilih **Data Sources**.

**Tombol Konfigurasi untuk Sumber Data Grafana**

Pada layar berikutnya, klik tombol **Add data source**.

**Tombol Tambah Sumber Data di Grafana**

Pilih **Prometheus** sebagai sumber data.

**Pilih Sumber Data Prometheus**

Untuk sumber Prometheus lokal, seperti yang dijelaskan dalam panduan ini, atur URL ke `http://localhost:9090`. Kebanyakan pengaturan lainnya bisa dibiarkan dalam nilai default. Namun, nilai Timeout non-default bisa ditambahkan jika diperlukan.

**Konfigurasi Sumber Data Prometheus**

Jika pengaturan sudah sesuai, klik tombol **Save & test** di bagian bawah layar.

**Simpan Sumber Data Prometheus**

Jika semua pengaturan benar, Grafana akan mengonfirmasi bahwa **Data source is working**.

**Pesan Konfirmasi tentang Sumber Data**

### Cara Mengimpor Dashboard Grafana

Dashboard menampilkan statistik dari node klien menggunakan tata letak yang lebih efektif dan standar. Anda bisa membuat dashboard kustom, tetapi Prometheus telah menyediakan dashboard yang mendukung statistik **Node Exporter**. Dashboard **Node Exporter Full** menggambarkan sebagian besar nilai yang dikumpulkan dari node klien. Lebih mudah mengimpor dashboard ini daripada membuat yang kustom.

Untuk mengimpor dashboard **Node Exporter**, ikuti langkah-langkah di bawah ini:

**Catatan:** Untuk membuat dashboard kustom, klik tombol **Dashboard** (ikon empat kotak), lalu pilih **+ New Dashboard**. Lihat panduan **Building a Dashboard** di Grafana untuk informasi lebih lanjut.

Kunjungi **Grafana Dashboard Library**. Masukkan **Node exporter** sebagai kata kunci pencarian.

**Cari di Pustaka Grafana**

Pilih entri untuk **Node Exporter Full**.

**Pilih Node Exporter Full**

Catat nomor ID atau gunakan tombol untuk menyalin ID ke clipboard. ID dari dashboard ini saat ini adalah **1860**.

**Detail Node Exporter Full**

Kembali ke dashboard Grafana. Pilih ikon **Dashboard** yang terdiri dari empat kotak, dan pilih **+ Import**.

**Pilih Opsi Impor**

Di kotak **Import via [grafana.com](http://grafana.com/)**, masukkan ID **1860** dari langkah sebelumnya. Lalu klik tombol **Load**.

**Impor Dashboard Node Exporter**

Pada layar berikutnya, konfirmasi detail impor. Pilih **Prometheus** sebagai sumber data, lalu klik tombol **Import**.

**Mengimpor Dashboard**

Dashboard **Node Exporter Full** langsung aktif. Dashboard ini menampilkan metrik kinerja dan status node klien, termasuk detail Memori, RAM, dan CPU. Beberapa menu dropdown di bagian atas layar memungkinkan pengguna untuk memilih host yang ingin diamati dan periode waktu yang akan ditonjolkan.

Contoh berikut menunjukkan bagaimana klien bereaksi saat dibebani program Python yang intens. Widget **CPU Busy** menunjukkan bagaimana CPU hampir mencapai kapasitas maksimal. Jika ini terjadi selama kondisi operasi normal, mungkin menandakan kebutuhan lebih banyak daya CPU.

## Webhook Endpoint untuk scale up dan scale down

Untuk melakukan scaling, server Express akan dikembangkan yang akan berinteraksi dengan API IDCloudhost. Endpoint ini akan bertanggung jawab untuk menambah atau mengurangi jumlah VM yang digunakan oleh sistem. Berikut algoritma dari masing-masing endpoint:

1. **Endpoint `/v1/scale-up`**:
   - Server akan menghitung jumlah VM yang terkait dengan Judge0.
   - Jika dibutuhkan, server akan membuat salinan (cloning) dari Judge0 seed VM.
   - Setelah VM baru dibuat, alamat IP publik yang terhubung akan dihapus.
   - Konfigurasi Traefik akan diperbarui untuk menambahkan IP VM baru ke load balancer.
   - Target Prometheus akan diperbarui untuk memasukkan VM baru ke dalam pemantauan.
2. **Endpoint `/v1/scale-down`**:

   - Server akan memeriksa jumlah VM salinan yang masih aktif.
   - Jika ada VM yang aktif, server akan memilih VM terbaru untuk dihapus.
   - VM yang dipilih kemudian akan dihapus dari sistem.
   - Konfigurasi Traefik akan diperbarui untuk menghapus VM yang dihapus dari load balancer.
   - Target Prometheus akan diperbarui untuk memantau VM yang tersisa.

   ```jsx
   const express = require("express");
   const axios = require("axios");
   const { exec } = require("child_process");
   require("dotenv").config();

   const app = express();
   const apiKey = process.env.API_KEY;
   app.use(express.json());

   const updateKrakenDConfig = (newHost, action) =>
     new Promise((resolve, reject) => {
       exec(
         `./scaling-script.sh ${action} "${newHost}"`,
         (error, stdout, stderr) => {
           if (error || stderr) {
             return reject(error || stderr);
           }
           resolve(stdout);
         }
       );
     });

   const getVMCount = async () => {
     const { data } = await axios.get(
       `https://api.idcloudhost.com/v1/jkt01/network/network/${process.env.PRIVATE_NETWORK_UUID}`,
       { headers: { apikey: apiKey } }
     );
     return data.resources_count - process.env.NON_JUDGE0_VM_COUNT;
   };

   const cloneVM = async (name) => {
     const { data } = await axios.post(
       `https://api.idcloudhost.com/v1/jkt01/user-resource/vm/clone?uuid=${process.env.JUDGE0_SEED_UUID}&name=${name}`,
       {},
       { headers: { apikey: apiKey } }
     );
     return data;
   };

   const deleteFloatingIP = async (vmUuid) => {
     const { data } = await axios.get(
       `https://api.idcloudhost.com/v1/jkt01/network/ip_addresses?billing_account_id=${process.env.BILLING_ACCOUNT_ID}`,
       { headers: { apikey: apiKey } }
     );
     const ip = data.find((ip) => ip.assigned_to === vmUuid);
     await axios.delete(
       `https://api.idcloudhost.com/v1/jkt01/network/ip_addresses/${ip.address}`,
       { headers: { apikey: apiKey } }
     );
     return ip;
   };

   const updatePrometheusTargets = async () => {
     const { data } = await axios.get(
       "https://api.idcloudhost.com/v1/jkt01/user-resource/vm/list",
       { headers: { apikey: apiKey } }
     );
     const ips = data
       .filter((vm) => vm.name.startsWith("judge0-child-"))
       .map((vm) => vm.private_ipv4);
     await axios.post(
       "http://103.179.56.99:4001/v1/update-prometheus-targets",
       { listOfClonesIp: ips }
     );
   };

   app.post("/v1/scale-up", async (req, res) => {
     try {
       const vmCount = await getVMCount();
       const newVmData = await cloneVM(`judge0-child-${vmCount}`);
       await deleteFloatingIP(newVmData.uuid);
       await updateKrakenDConfig(
         `http://${newVmData.private_ipv4}:2358`,
         "add"
       );
       await updatePrometheusTargets();
       res.send({ newVmData });
     } catch (error) {
       res.status(500).send({ error: error.message });
     }
   });

   app.post("/v1/scale-down", async (req, res) => {
     try {
       const { data } = await axios.get(
         "https://api.idcloudhost.com/v1/jkt01/user-resource/vm/list",
         { headers: { apikey: apiKey } }
       );
       const vmList = data.filter((vm) => vm.name.startsWith("judge0-child-"));
       if (!vmList.length)
         return res.send({ message: "No child VM, scale down aborted" });
       const vmToDelete = vmList.sort(
         (a, b) => new Date(b.created_at) - new Date(a.created_at)
       )[0];
       await axios.delete(
         `https://api.idcloudhost.com/v1/jkt01/user-resource/vm?uuid=${vmToDelete.uuid}`,
         { headers: { apikey: apiKey } }
       );
       await updateKrakenDConfig(
         `http://${vmToDelete.private_ipv4}:2358`,
         "remove"
       );
       await updatePrometheusTargets();
       res.send({ message: "VM Deleted", vmDeleted: vmToDelete });
     } catch (error) {
       res.status(500).send({ error: error.message });
     }
   });

   const PORT = process.env.PORT || 3000;
   app.listen(PORT, () => console.log(`Server running on port ${PORT}`));
   ```

## Implementasi Alerting

Pada bagian ini kita akan mendefinisikan Trigger ketika event scale up atau scale down harus dijalankan. Hal dasar yang harus diketahui ketika

Keadaan yang harus dipenuhi agar sebuah event ter trigger disebut alert rules

Apa aksi yang harus dilakukan ketika sebuah alert rules disebut dengan contact points

Pada panduan ini hanya akan dilakukan kalkulasi alert rule dengan CPU Load

### Menghitung rata-rata CPU Load

Kita sudah mendapatkan data melalu prometheus, berdasarkan data ini kita dapat menentukan rata rata CPU Load dari sistem.

Kita dapat menggunakan bahasa query dari prometehus yang bernama promql, kita akan membuat sebuah alert rule menggunakan bahasa promp ini

Kita ingin mengetahui rata rata CPU Load dari semua service yang ada dalam waktu 3 menit terakhir

Berikut logika diatas dalam bentuk query promql

```sql
100 - (avg(
    rate(node_cpu_seconds_total{job=~"judge0_seed|judge0_clone", mode="idle"}[3m])
)*100)
```

Maksud dasar dari query diatas adalah untuk menghitung persentase penggunaan CPU (CPU Usage) dari server yang memiliki job dengan nama judge0_seed atau judge0_clone dalam tiga menit terakhir

Ada beberapa hal yang menjadi perhatian

- `node_cpu_seconds_total` adalah metrik yang merepresentasikan waktu total yang dihabiskan oleh CPU dalam berbagai mode seperti idle, user, system, dll.
- Label `{job=~"judge0_seed|judge0_clone", mode="idle"}` akan mengambil waktu yang dihabiskan oleh cpu dalam masa idle pada server dengan job name judge0_seed atau judge0_clone.
- Fungsi`rate` menghitung tingkat perubahan (rate) dari **`node_cpu_seconds_total`** dalam interval waktu 3 menit (**[3m]**).
- Setelah menghitung rate dari waktu idle CPU, hasilnya dikalikan 100 untuk mengonversi menjadi persentase waktu idle.
- **`avg`**Mengambil rata-rata dari semua CPU yang disaring oleh query (jika ada beberapa core CPU).
- **`100 - ...`**Mengurangi hasil dari persentase waktu idle dari 100 untuk mendapatkan persentase penggunaan CPU (CPU utilization).
- Hasil akhirnya adalah rata-rata persentase penggunaan CPU selama 3 menit terakhir untuk server dengan job name **judge0_seed** atau **judge0_clone**.

### Mengatur Alert Rule Untuk Event Scale Up

#### 1. Enter alert rule name

Masukan nama dari alert rule

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/5f2a7f83-0f94-488c-9404-d54249a0f222/image.png)

#### 2. Query and Alert Condition

Gambar dibawah adalah pengaturan untuk query dan treshold.

Gunakan query untuk menghitung average CPU yang sudah kita definisikan sebelumnya

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/a3acd991-ed39-461d-b3d1-1b2f62bc5b07/image.png)

Lalu untuk treshold, kita tidak memerlukan fungsi reduce karena query sudah merupakan satu nilaiI

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/a3580c90-e175-4f44-b19a-ba570503b696/image.png)

Pengaturan diatas menentukan bahwa, grafana akan melakukan alert pada saat Average CPU Load lebih dari 70%

#### 3. Set Evaluation Behaviour

Gambar dibawah Menunjukan pengaturan dalam pengeturan inerval evaluasi sistem. Pengaturan ini akan menentukan seberapa sering query dijalankan dan seberapa sering grafana akan membandingkan hasil dari query dengan treshold yang kita tentukan.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/32d0e6c0-6f38-49a8-a40b-5c0faf2cdef0/image.png)

1. Folder

Kita akan mengelompokah rule pada folder scale up

1. Evaluation grouup and interval

Kita membuat evaluaiton evaluation group bernama `eval_10s` yang akan mengevaluasi rule setiap sepuluh detik

1. Pending Period

Mengatur pending period menjadi `none` artinya ketika treshold terpenuhi, alert rule akan langsung mentrigger api untuk melakukan scaling.

1. Configure No Data and error handling

Tidak di set

#### 4. Configure labels and notifications

Pada menu contact point pilih webhook scale up yang sudah dibuat sebelumnya

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/bd5c9d79-98e5-4217-acc5-418b491aae1c/image.png)

### Mengatur alert rule untuk event scale down

#### 1. Enter alert rule name

Masukan nama dari alert rule

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/abd97cc7-6473-47d0-a5cb-4ecf752670bc/image.png)

#### 2. Define Query and Alert Condition

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/1f407776-b0f4-4ff0-949f-d6c1b11cb980/image.png)

Sama seperti scalle up gunakan query untuk menghitung Average CPU Load yang sduah ditentukan sebelumnya

Lalu tentukan threshold seperti ini

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/4fc24116-f30a-43e2-87a6-ebdcb00c9c7b/image.png)

Disini kita telah mengatur alert rule scale down akan di jalankan ketika average CPU kurang dari 30%.

#### 3. Set evaluation behaviour

Berikut adalah pengaturan evaluasi sistem

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/975022b2-bd0b-438b-839d-8fcaf2528cf4/image.png)

1. Folder

Dikelompokan dalam fodler scale down

1. Evaluation groudp and interval

Menggunakan interval group yang sama dengan alert rule scale up yaitu `eval10s` yang akan mengevaluasi rule setiap 10 detik

1. Pending Period

Pending selama 2 menit untuk mengantisipasi ketika terjadi sudden drop, karena scale up merupakan proses yang lama

lalu kelebihan server tidka menimpbulakan instability hanya menambah cost. sehingga mengantisipasi drop yang hanya sementara

akan lebih baik jika kita memiliki server lebih lebih lama jika sewaktu waktu terjadi spike karena proses scale up lebih lama dari scale down

1. Configure No Data and error handling

Tidak di set

#### 4. Configure labels and notification

Pada menu contact point pilih webhook scale down yang sudah dibuat sebelumnya

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/a780a314-a324-4050-aaa4-d4498b8af326/775d2998-585f-4bd0-b12b-d8400bb56ee6/image.png)

## Konsep Testing

Untuk melakukan testing fitur scale down dan scale up kita harus bisa mengatur secara presisi berapa banyak request yang dikimkan ke server. Artinya kita harus bisa mengendalikan Request per second (RPS), ini diperlukan agar kita bisa mengontrol CPU Load dari sistem secara presisi.

Selain itu kita harus bisa mengatur testing yang ramping artinya testig yang seiring waktu meningkat untuk mensimulasikan trafic pada sehingga mentrigger scale up lalu menurunkan traffic untuk mensimulasikan trafic yang sepi sehingga mentrigger scale down

Untuk memenuhi kebutuhan ini kita akan menggunakna executor dari K6 yaitu `rampign-arrival-rate` . Executor ini memungkinkan kita untuk mengatur RPS secara presisi dan menaikan atau menurunkan RPS seiring waktu.

## Merancang Kode Testing

Pada kode testing dibawah ini kita akan mengirimkan POST Request pada endpoint `/v1/subm`issions-dev?wait=true&base64_encoded=false'` yang berfungsi untuk mengeksekusi kode dan akan menghasilkan response berupa hasil dari eksekusi kode.

```jsx
import http from 'k6/http';
import { check } from 'k6';

// 1. Source Codes
const sourceCodes = [
  `def leetcode_function(nums, target):
  for i in range(len(nums)):
    for j in range(i + 1, len(nums)):
      if nums[i] + nums[j] == target:
        return [i, j]
  return []
print('LeetCode Function Result:', leetcode_function([2, 7, 11, 15], 9))

`,
...
// other code
];

// 2. Options
export const options = {
  scenarios: {
    ramping_test: {
      executor: 'ramping-arrival-rate',
      startRate: 0,
      timeUnit: '1s',
      preAllocatedVUs: 2,
      maxVUs: 30,
      stages: [
        { duration: '3m', target: 3 },
        { duration: '9m', target: 6 },
        { duration: '5m', target: 1 },
      ],
    },
  },
  discardResponseBodies: true,
};

// 3. Default Function
export default function () {
	// [a]
  let url = 'https://submissions.pojokoding.my.id/v1/subm`issions-dev?wait=true&base64_encoded=false';

	// [b]
  let headers = {
    'Authorization': '43304a11-4ece-4938-8a81-c4113ed10cf6',
    'Content-Type': 'application/json',
  };

	// [c]
  let randomIndex = Math.floor(Math.random() * sourceCodes.length);
  let randomSourceCode = sourceCodes[randomIndex];

	// [d]
  let body = JSON.stringify({
    source_code: randomSourceCode,
    language_id: 71,
  });

	// [e]
  let res = http.post(url, body, { headers: headers });

	// [f]
  check(res, {
    'status is 200': (r) => r.status === 200,
  });
}
```

1. Source Codes
   1. `const sourceCodes` : Ini adalah variabel berisi array string kode yang akan dikirmkan bersama body request, value akan dipilih secara random
2. Options
   1. **`scenarios`**: Mengatur skenario pengujian beban (load testing) yang akan dijalankan oleh K6. Di dalamnya, terdapat definisi satu skenario bernama `ramping_test`.
      1. **`ramping_test`**: Nama skenario pengujian. Nama ini bisa diubah sesuai kebutuhan.
         1. **`executor`**: Jenis eksekutor yang menentukan bagaimana virtual users (VU) akan diatur.
         2. **`ramping-arrival-rate`**: Eksekutor ini digunakan untuk secara bertahap meningkatkan atau mengurangi jumlah request yang tiba pada sistem, dikendalikan oleh pengaturan rate (RPS) selama periode waktu yang ditentukan.
         3. **`startRate`**: Menentukan **rate awal** dari request yang dikirim ke sistem saat pengujian dimulai. Dalam hal ini, pengujian dimulai dengan **0 request per second (RPS)** dan akan meningkat berdasarkan pengaturan pada `stages`.
         4. **`timeUnit`**: Menentukan satuan waktu untuk mengukur tingkat request. Di sini, setiap request per second (RPS) diukur dalam interval **per detik** (`1s`), yang berarti jumlah request yang tiba diatur dalam hitungan per detik.
         5. **`preAllocatedVUs`**: Menentukan jumlah **virtual users (VU)** yang akan dialokasikan **sebelum pengujian dimulai**. Dalam kasus ini, **2 VU** dialokasikan untuk menangani request saat pengujian dimulai.
         6. **`maxVUs`**: Menentukan jumlah **maksimum VU** yang bisa digunakan untuk pengujian ini. **30 VU** adalah batas atas yang digunakan untuk mengatur skala maksimal dari pengujian. Jika diperlukan lebih banyak VU untuk memenuhi rate RPS yang diminta, hingga 30 VU akan dialokasikan.
         7. **`stages`**: Tahapan yang mengatur bagaimana tingkat Request Per Second (RPS) akan berubah selama pengujian.
            1. **{ duration: '3m', target: 3 }**:
               - Tahap pertama berlangsung selama **3 menit**, dengan target untuk mencapai **3 request per second (RPS)** di akhir tahap ini. Ini adalah proses ramp-up dari 0 RPS hingga 3 RPS.
            2. **{ duration: '9m', target: 6 }**:
               - Tahap kedua berlangsung selama **9 menit**, di mana tingkat kedatangan request meningkat secara bertahap hingga mencapai **6 RPS**.
            3. **{ duration: '5m', target: 1 }**:
               - Tahap ketiga berlangsung selama **5 menit**, dan dalam tahap ini, tingkat RPS menurun **dari 6 RPS menjadi 1 RPS**. Ini merupakan proses ramp-down atau pengurangan beban.
   2. **`discardResponseBodies`**: Pengaturan ini akan **mengabaikan body respons** dari setiap request yang dikirim. Ini berguna untuk menghemat memori selama pengujian beban, terutama jika body respons tidak penting untuk analisis hasil pengujian.
3. Default Function

   1. **URL**
      Variabel `url` berisi alamat endpoint untuk melakukan request POST, yaitu `https://submissions.pojokoding.my.id/v1/submissions-dev?wait=true&base64_encoded=false`.
   2. **Headers**
      Variabel `headers` menyimpan **header HTTP** yang akan dikirim bersama dengan request. Ada dua header yang disetel: - **Authorization**: Berisi token atau kunci API (`43304a11-4ece-4938-8a81-c4113ed10cf6`), yang digunakan untuk otentikasi agar bisa mengakses API. - **Content-Type**: Mengindikasikan tipe data yang dikirim dalam request adalah JSON (`application/json`).
   3. **Random Source Code Selection**
      Baris ini memilih **source code secara acak** dari array `sourceCodes`. Variabel `randomIndex` menghasilkan angka acak menggunakan `Math.random()` dan `Math.floor()` untuk mendapatkan indeks yang valid dari array `sourceCodes`. Selanjutnya, kode yang dipilih secara acak disimpan di variabel `randomSourceCode`.
   4. **Request Body**
      Variabel `body` berisi **data JSON yang dikirim** dalam request POST. Dalam body ini terdapat dua parameter: - **source_code**: Kode sumber yang diambil secara acak dari `sourceCodes`. - **language_id**: ID bahasa pemrograman yang digunakan, dalam hal ini 71 (mungkin mengacu pada bahasa pemrograman spesifik seperti Python atau C++). Kode sumber dan ID bahasa dikirim ke API untuk diproses.
   5. **HTTP POST Request**
      Fungsi `http.post` digunakan untuk **mengirim request POST** ke `url` yang sudah didefinisikan. Parameter yang dikirimkan adalah `url`, `body`, dan objek `headers`. - **url**: Alamat endpoint API yang akan diakses. - **body**: Data yang dikirim dalam format JSON. - **headers**: Header untuk autentikasi dan informasi tipe konten.
   6. **Response Validation**
      Fungsi `check` digunakan untuk **memeriksa status respons** dari server. - `status is 200`: Mengecek apakah status HTTP dari respons adalah **200** (OK), yang menunjukkan bahwa permintaan berhasil diproses. Jika statusnya 200, check akan mengembalikan `true`, jika tidak, `false`.

   Setiap bagian ini membantu memastikan pengiriman data secara acak ke API dan memverifikasi bahwa respons dari server sesuai dengan ekspektasi.

## Menjalankan Testing

Pastikan sudah menginstall k6 lalu Buka terminal untuk menjalankan command berikut untuk menjalankan testing

```jsx
k6 run filetest.js
```

## Analisis Hasil Testing

BELUM ADA

## Konsiderasi

**PERHITUNGAN SCALE UP DAN SCALE DOWN**

dalam perhitungan scale up dan scale down identifikasi apa yang menjadi resource utama yang dibutuhkan resource anda, pada panduan kali ini judge0 hanya menggunakan CPU dan sangat sedikit ram sehingga kalkulasi alerting hanya menggunakan parameter CPU

**KEAMANAN**

panduan ini sama sekali tidak menerapkan keamanan pada API Gateway sehingga rentan

http://mochi.com

kelapa.com
